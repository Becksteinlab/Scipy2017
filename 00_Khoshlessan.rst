:author: Mahzad Khoshlessan
:email: mkhoshle@asu.edu
:institution: Arizona State University
:corresponding:

:author: Oliver Beckstein
:email: obeckste@asu.edu 
:institution: Arizona State University 

------------------------------------------------
A Benchmark Suite for Measuring Parallel Computing Performance in MDAnalysis Library
------------------------------------------------

Brief abstract
--------------
In the present study, a benchmark suite is designed that can be used to evaluate performance for
parallel map-reduce type analysis and use it to investigate the performance of
MDAnalysis_ with the Dask_ library for task-graph based computing
[Khoshlessan2017]_. Benchmarks are performed both on a single node and across multiple
nodes on different high performanc computing (HPC) resources.
The benchmark suit consists different Molecular dynamics file format and different trajectory sizes.
In this paper, we primarily discuss the effect of file format and hardware on the performance
and try to identify performance bottlenecks, which can be used for further optimization and bringing HPC into MDAnalysis library.


Long description
----------------

MDAnalysis_ is a Python library that provides users with access to raw simulation data that allows structural and temporal analysis of molecular dynamics (MD) trajectories generated by all major MD simulation packages.
The size of these trajectories is growing as the simulation times is being extended from micro-seconds to mili-seconds.
Therefore, there is a need for high performance computing (HPC) approaches to increase the throughput.
MDAnalysis does not yet provide a standard interface for parallel analysis; instead, various existing parallel libraries are currently used to parallelize MDAnalysis-based code.
However, a standardized benchmark suite that focuses on helping users evaluate the performance of the MDAnalysis library is not available in the current community.
Present study aims to identify possible approaches for bringing HPC into MDAnalysis.
In this paper, we present a benchmark suite that can be used to evaluate performance for parallel map-reduce type analysis along with the Dask_ library for task-graph based distributed computing.                       
A range of commonly used MD file formats (CHARMM/NAMD DCD, Gromacs XTC, Amber NetCDF) and different trajectory sizes are benchmarked on different high performance computing (HPC) resources.
Different storages like solid state drives (SSDs), hard disk drives (HDDs) and Lustre file system are also tested to examine effect of storage location on the performance.
The benchmarks are performed both on a single node and across multiple nodes using multiprocessing and distributed schedulers in Dask library.
Overall, our results show strong dependency to hardware and file formats.
On a single node we found multiprocessing scheduler to provide slightly better scaling than distributed scheduler on multiple nodes.
According to our results, although Map-Reduce job is pleasantly parallel and all processors have the same amount of work to do, some of the processes are much slower than the others in some tests.
We hypothesize that weak performance gains from distributed scheduler is likely due to contention on the network that may slow down individual tasks and lead to overall waits and poor load balancing.
All in all, obtaining good parallel performance with a Map-Reduce approach for trajectory analysis is strongly dependent on efficient transfer of trajectory data to memory.
Present study provides guidelines for how the choice of trajectory format along with the hardware can lead to good performance.
At the end, we also suggest the promising approaches that can be done to get the best possible performance out of MDAnalysis library.


Keywords
--------
   MDAnalysis, High Performance Computing, Dask, Map-Reduce job, File formats


The draft of our benchmark study including all of our data is available on figshare at DOI
10.6084/m9.figshare.4695742_; 

Data Files
----------

The topology file (PSF format) and the trajectory (DCD) used for the benchmark
can be downloaded from dropbox

- adk4AKE.psf_
- 1ake_007-nowater-core-dt240ps.dcd_

Files in XTC and NetCDF formats are generated from the DCD.

Tested libraries
----------------

- MDAnalysis_ 0.15.0
- Dask_ 0.12.0 (also 0.13.0)
- Distributed_ 1.14.3 (also 1.15.1)
- NumPy_ 1.11.2 (also 1.12.0)


References
----------
.. [Khoshlessan2017] Khoshlessan, Mahzad; Beckstein, Oliver (2017): Parallel analysis in the MDAnalysis Library: Benchmark of Trajectory File Formats. figshare. doi:10.6084/m9.figshare.4695742


.. _MDAnalysis: http://mdanalysis.org
.. _Dask: http://dask.pydata.org
.. _Distributed: https://distributed.readthedocs.io/
.. _NumPy: http://numpy.scipy.org/
.. _10.6084/m9.figshare.4695742: https://doi.org/10.6084/m9.figshare.4695742
.. _adk4AKE.psf: https://www.dropbox.com/sh/ln0klc9j7mhvxkg/AAAL5eP1vrn0tK-67qVDnKeua/Trajectories/equilibrium/adk4AKE.psf
.. _1ake_007-nowater-core-dt240ps.dcd: https://www.dropbox.com/sh/ln0klc9j7mhvxkg/AABSaNJ0fRFgY1UfxIH_jWtka/Trajectories/equilibrium/1ake_007-nowater-core-dt240ps.dcd
